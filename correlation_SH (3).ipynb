{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation between 'fuel_diff' and 'fuel_level': -0.0788 (p-value: 0.0000)\n",
      "Spearman correlation between 'fuel_diff' and 'speed_generate': -0.2757 (p-value: 0.0000)\n",
      "Spearman correlation between 'fuel_diff' and 'batteryVoltage': -0.0111 (p-value: 0.0000)\n",
      "Spearman correlation between 'fuel_diff' and 'altitude': -0.0603 (p-value: 0.0000)\n",
      "Spearman correlation between 'fuel_diff' and 'gnssHDOP': 0.0069 (p-value: 0.0000)\n",
      "Spearman correlation between 'fuel_diff' and 'gnssPDOP': -0.0271 (p-value: 0.0000)\n",
      "Spearman correlation between 'fuel_diff' and 'heading': -0.0022 (p-value: 0.0126)\n",
      "Spearman correlation between 'fuel_diff' and 'lat': 0.0160 (p-value: 0.0000)\n",
      "Spearman correlation between 'fuel_diff' and 'lon': -0.0031 (p-value: 0.0004)\n",
      "Spearman correlation between 'fuel_diff' and 'axisX': -0.0120 (p-value: 0.0000)\n",
      "Spearman correlation between 'fuel_diff' and 'axisY': -0.0462 (p-value: 0.0000)\n",
      "Spearman correlation between 'fuel_diff' and 'axisZ': -0.1509 (p-value: 0.0000)\n",
      "Spearman correlation between 'fuel_diff' and 'distance (km)': -0.2908 (p-value: 0.0000)\n",
      "Spearman correlation between 'fuel_diff' and 'Fuel Capacity (L)_x': -0.0079 (p-value: 0.0000)\n",
      "Spearman correlation between 'fuel_diff' and 'Engine CC': -0.0212 (p-value: 0.0000)\n",
      "Spearman correlation between 'fuel_diff' and 'BDM': -0.0330 (p-value: 0.0000)\n",
      "Spearman correlation between 'fuel_diff' and 'BTM': -0.0380 (p-value: 0.0000)\n",
      "Spearman correlation between 'fuel_diff' and 'unix_timestamp': -0.0033 (p-value: 0.0002)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# load your dataframe, assuming 'fuel_diff' is one of the columns\n",
    "df = pd.read_csv('230611_GMM.csv')\n",
    "\n",
    "# Convert to datetime object\n",
    "df['deviceTime'] = pd.to_datetime(df['deviceTime'])\n",
    "# Convert to Unix timestamp\n",
    "df['unix_timestamp'] = df['deviceTime'].apply(lambda x: x.timestamp())\n",
    "\n",
    "# specify the variables you want to correlate with 'fuel_diff'\n",
    "variable_names = df.drop(['deviceTime', 'date', 'starting', 'ending', 'label', 'new_vehicle_id', \n",
    "                          'fuel_diff', 'vehicleId', 'Brand', 'Model'], axis=1, errors = 'ignore').columns.tolist()\n",
    "\n",
    "for variable_name in variable_names:\n",
    "    rho, p_value = spearmanr(df[variable_name], df['fuel_diff'])\n",
    "    print(f\"Spearman correlation between 'fuel_diff' and '{variable_name}': {rho:.4f} (p-value: {p_value:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/snap/jupyter/6/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3296: DtypeWarning: Columns (22) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('230529_GMM.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1134675 entries, 0 to 1134674\n",
      "Data columns (total 26 columns):\n",
      " #   Column          Non-Null Count    Dtype  \n",
      "---  ------          --------------    -----  \n",
      " 0   new_vehicle_id  1134675 non-null  object \n",
      " 1   vehicleId       1134675 non-null  object \n",
      " 2   deviceTime      1134675 non-null  object \n",
      " 3   fuel            1134675 non-null  float64\n",
      " 4   speed_generate  1134675 non-null  float64\n",
      " 5   batteryVoltage  1134675 non-null  float64\n",
      " 6   altitude        1134675 non-null  float64\n",
      " 7   gnssHDOP        1134675 non-null  float64\n",
      " 8   gnssPDOP        1134675 non-null  float64\n",
      " 9   heading         1134675 non-null  float64\n",
      " 10  lat             1134675 non-null  float64\n",
      " 11  lon             1134675 non-null  float64\n",
      " 12  axisX           1134675 non-null  float64\n",
      " 13  axisY           1134675 non-null  float64\n",
      " 14  axisZ           1134675 non-null  float64\n",
      " 15  distance (km)   1134675 non-null  float64\n",
      " 16  fuel_diff       1134675 non-null  float64\n",
      " 17  ending          1134675 non-null  bool   \n",
      " 18  date            1134675 non-null  object \n",
      " 19  starting        1134675 non-null  bool   \n",
      " 20  label           1134675 non-null  object \n",
      " 21  Brand           1134675 non-null  object \n",
      " 22  Model           1134675 non-null  object \n",
      " 23  Engine CC       1134675 non-null  int64  \n",
      " 24  BDM             1134675 non-null  int64  \n",
      " 25  BTM             1134675 non-null  int64  \n",
      "dtypes: bool(2), float64(14), int64(3), object(7)\n",
      "memory usage: 209.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['VID ', 'Brand', 'Model', 'Engine CC', 'BDM', 'BTM'], dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(df, df2, left_on='vehicleId', right_on='VID ', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['new_vehicle_id', 'vehicleId', 'deviceTime', 'fuel', 'speed_generate',\n",
       "       'batteryVoltage', 'altitude', 'gnssHDOP', 'gnssPDOP', 'heading', 'lat',\n",
       "       'lon', 'axisX', 'axisY', 'axisZ', 'distance (km)', 'fuel_diff',\n",
       "       'ending', 'date', 'starting', 'label', 'VID ', 'Brand', 'Model',\n",
       "       'Engine CC', 'BDM', 'BTM'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.drop(['VID '], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1134675 entries, 0 to 1134674\n",
      "Data columns (total 26 columns):\n",
      " #   Column          Non-Null Count    Dtype  \n",
      "---  ------          --------------    -----  \n",
      " 0   new_vehicle_id  1134675 non-null  object \n",
      " 1   vehicleId       1134675 non-null  object \n",
      " 2   deviceTime      1134675 non-null  object \n",
      " 3   fuel            1134675 non-null  float64\n",
      " 4   speed_generate  1134675 non-null  float64\n",
      " 5   batteryVoltage  1134675 non-null  float64\n",
      " 6   altitude        1134675 non-null  float64\n",
      " 7   gnssHDOP        1134675 non-null  float64\n",
      " 8   gnssPDOP        1134675 non-null  float64\n",
      " 9   heading         1134675 non-null  float64\n",
      " 10  lat             1134675 non-null  float64\n",
      " 11  lon             1134675 non-null  float64\n",
      " 12  axisX           1134675 non-null  float64\n",
      " 13  axisY           1134675 non-null  float64\n",
      " 14  axisZ           1134675 non-null  float64\n",
      " 15  distance (km)   1134675 non-null  float64\n",
      " 16  fuel_diff       1134675 non-null  float64\n",
      " 17  ending          1134675 non-null  bool   \n",
      " 18  date            1134675 non-null  object \n",
      " 19  starting        1134675 non-null  bool   \n",
      " 20  label           1134675 non-null  object \n",
      " 21  Brand           1134675 non-null  object \n",
      " 22  Model           1134675 non-null  object \n",
      " 23  Engine CC       1134675 non-null  int64  \n",
      " 24  BDM             1134675 non-null  object \n",
      " 25  BTM             1134675 non-null  object \n",
      "dtypes: bool(2), float64(14), int64(1), object(9)\n",
      "memory usage: 218.6+ MB\n"
     ]
    }
   ],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('230529_GMM.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pingouin import kruskal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>ddof1</th>\n",
       "      <th>H</th>\n",
       "      <th>p-unc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Kruskal</th>\n",
       "      <td>Brand</td>\n",
       "      <td>11</td>\n",
       "      <td>10200.084686</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Source  ddof1             H  p-unc\n",
       "Kruskal  Brand     11  10200.084686    0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kruskal(data = df, dv ='fuel_diff', between ='Brand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>ddof1</th>\n",
       "      <th>H</th>\n",
       "      <th>p-unc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Kruskal</th>\n",
       "      <td>Model</td>\n",
       "      <td>14</td>\n",
       "      <td>12959.463182</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Source  ddof1             H  p-unc\n",
       "Kruskal  Model     14  12959.463182    0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kruskal(data = df, dv ='fuel_diff', between ='Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>ddof1</th>\n",
       "      <th>H</th>\n",
       "      <th>p-unc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Kruskal</th>\n",
       "      <td>label</td>\n",
       "      <td>2</td>\n",
       "      <td>155552.539193</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Source  ddof1              H  p-unc\n",
       "Kruskal  label      2  155552.539193    0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kruskal(data = df, dv ='fuel_diff', between ='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_group = df['label'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scikit_posthocs as sp\n",
    "data = [df[df['label']==\"normal\"]['fuel_diff'],\n",
    "        df[df['label']==\"abnormal\"]['fuel_diff'],\n",
    "        df[df['label']==\"refuel\"]['fuel_diff']]\n",
    "result = sp.posthoc_dunn(data, p_adjust = 'bonferroni')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1    2    3\n",
      "1  1.0  0.0  0.0\n",
      "2  0.0  1.0  0.0\n",
      "3  0.0  0.0  1.0\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = np.array(df[df['label']==\"normal\"]['fuel_diff'])\n",
    "abnormal = np.array(df[df['label']==\"abnormal\"]['fuel_diff'])\n",
    "refuel = np.array(df[df['label']==\"refuel\"]['fuel_diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mann-Whitney U statistic: 114583049700.0\n",
      "Mann-Whitney U p-value: 0.0\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# Perform Mann-Whitney U test\n",
    "statistic, p_value = mannwhitneyu(normal, abnormal)\n",
    "\n",
    "# Print the test results\n",
    "print(\"Mann-Whitney U statistic:\", statistic)\n",
    "print(\"Mann-Whitney U p-value:\", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boruta\n",
      "  Downloading Boruta-0.3-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.6/56.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.10.4 in /home/ubuntu/snap/jupyter/common/lib/python3.7/site-packages (from boruta) (1.21.6)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /home/ubuntu/snap/jupyter/common/lib/python3.7/site-packages (from boruta) (1.7.3)\n",
      "Requirement already satisfied: scikit-learn>=0.17.1 in /home/ubuntu/snap/jupyter/common/lib/python3.7/site-packages (from boruta) (1.0.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ubuntu/snap/jupyter/common/lib/python3.7/site-packages (from scikit-learn>=0.17.1->boruta) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ubuntu/snap/jupyter/common/lib/python3.7/site-packages (from scikit-learn>=0.17.1->boruta) (3.1.0)\n",
      "Installing collected packages: boruta\n",
      "Successfully installed boruta-0.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/snap/jupyter/common/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "df = pd.read_csv('230620_GMM.csv')\n",
    "# Convert to datetime object\n",
    "df['deviceTime'] = pd.to_datetime(df['deviceTime'])\n",
    "# Convert to Unix timestamp\n",
    "df['unix_timestamp'] = df['deviceTime'].apply(lambda x: x.timestamp())\n",
    "\n",
    "# initialize OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# fit and transform the data\n",
    "encoded = encoder.fit_transform(df[['label']]).toarray()\n",
    "\n",
    "# create new columns in the original dataframe with the encoded values\n",
    "encoded_df = pd.DataFrame(encoded, columns=encoder.get_feature_names(['label']))\n",
    "df = pd.concat([df, encoded_df], axis=1)\n",
    "\n",
    "df = df.drop(['date', 'label', 'vehicleId', 'ending', 'starting', 'gnssPDOP', 'gnssHDOP'], axis = 1)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Select only the columns that have numeric data types and exclude target\n",
    "numeric_cols = df.select_dtypes(include=['float', 'int']).columns\n",
    "numeric_cols = numeric_cols.drop('fuel_diff')\n",
    "\n",
    "# Apply MinMaxScaler only on the numeric columns\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = df.copy()\n",
    "df_scaled[numeric_cols] = scaler.fit_transform(df_scaled[numeric_cols])\n",
    "\n",
    "# The object columns remain unchanged\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "val_mask = df_scaled['new_vehicle_id'].isin(['v1', 'v7', 'v10', 'v5', 'v17'])\n",
    "test_mask = df_scaled['new_vehicle_id'].isin(['v3', 'v8', 'v28', 'v32', 'v2'])\n",
    "train_mask = ~df_scaled['new_vehicle_id'].isin(np.concatenate((val_mask, test_mask)))\n",
    "X_train = df_scaled.loc[train_mask, :].drop(columns=['new_vehicle_id', 'deviceTime', 'fuel_diff' ,'fuel_level'])\n",
    "y_train = df_scaled.loc[train_mask, 'fuel_diff']\n",
    "X_val = df_scaled.loc[val_mask, :].drop(columns=['new_vehicle_id', 'deviceTime', 'fuel_diff', 'fuel_level'])\n",
    "y_val = df_scaled.loc[val_mask, 'fuel_diff']\n",
    "X_test = df_scaled.loc[test_mask, :].drop(columns=['new_vehicle_id', 'deviceTime', 'fuel_diff','fuel_level'])\n",
    "y_test = df_scaled.loc[test_mask, 'fuel_diff']\n",
    "\n",
    "\n",
    "# Define the LightGBM dataset\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "val_data = lgb.Dataset(X_val, label=y_val)\n",
    "\n",
    "# Define the hyperparameters\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'l2',\n",
    "    'num_leaves': 30,\n",
    "    'learning_rate': 0.1,\n",
    "    'feature_fraction': 0.8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Booster' object has no attribute 'get_params'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-21f6af647b38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# find all relevant features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mfeat_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# check selected features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/snap/jupyter/common/lib/python3.7/site-packages/boruta/boruta_py.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \"\"\"\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweak\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/snap/jupyter/common/lib/python3.7/site-packages/boruta/boruta_py.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0;31m# number of features that aren't rejected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m                 \u001b[0mnot_rejected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_reg\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m                 \u001b[0mn_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tree_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnot_rejected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/snap/jupyter/common/lib/python3.7/site-packages/boruta/boruta_py.py\u001b[0m in \u001b[0;36m_get_tree_num\u001b[0;34m(self, n_feat)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_tree_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         \u001b[0mdepth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_depth'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mdepth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Booster' object has no attribute 'get_params'"
     ]
    }
   ],
   "source": [
    "from boruta import BorutaPy\n",
    "\n",
    "# Convert X DataFrame to numpy array\n",
    "X = X_train.to_numpy()\n",
    "y = y_train.to_numpy()\n",
    "\n",
    "# define Boruta feature selection method\n",
    "feat_selector = BorutaPy(model, n_estimators='auto', verbose=2, random_state=1)\n",
    "\n",
    "# find all relevant features\n",
    "feat_selector.fit(X, y)\n",
    "\n",
    "# check selected features\n",
    "print(feat_selector.support_)  #Should we accept the feature\n",
    "\n",
    "# check ranking of features\n",
    "print(feat_selector.ranking_) #Rank 1 is the best\n",
    "\n",
    "# call transform() on X to filter it down to selected features\n",
    "X_filtered = feat_selector.transform(X)  #Apply feature selection and return transformed data\n",
    "\n",
    "\"\"\"\n",
    "Review the features\n",
    "\"\"\"\n",
    "# zip feature names, ranks, and decisions \n",
    "feature_ranks = list(zip(feature_names, \n",
    "                         feat_selector.ranking_, \n",
    "                         feat_selector.support_))\n",
    "\n",
    "# print the results\n",
    "for feat in feature_ranks:\n",
    "    print('Feature: {:<30} Rank: {},  Keep: {}'.format(feat[0], feat[1], feat[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True False  True  True False  True  True  True False  True\n",
      " False False False]\n",
      "[1 1 1 3 1 1 2 1 1 1 5 1 4 7 6]\n",
      "Feature: speed_generate                 Rank: 1,  Keep: True\n",
      "Feature: batteryVoltage                 Rank: 1,  Keep: True\n",
      "Feature: altitude                       Rank: 1,  Keep: True\n",
      "Feature: heading                        Rank: 3,  Keep: False\n",
      "Feature: lat                            Rank: 1,  Keep: True\n",
      "Feature: lon                            Rank: 1,  Keep: True\n",
      "Feature: axisX                          Rank: 2,  Keep: False\n",
      "Feature: axisY                          Rank: 1,  Keep: True\n",
      "Feature: axisZ                          Rank: 1,  Keep: True\n",
      "Feature: distance (km)                  Rank: 1,  Keep: True\n",
      "Feature: Fuel Capacity (L)              Rank: 5,  Keep: False\n",
      "Feature: unix_timestamp                 Rank: 1,  Keep: True\n",
      "Feature: label_abnormal                 Rank: 4,  Keep: False\n",
      "Feature: label_normal                   Rank: 7,  Keep: False\n",
      "Feature: label_refuel                   Rank: 6,  Keep: False\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from boruta import BorutaPy\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Convert X DataFrame to numpy array\n",
    "X = X_train.to_numpy()\n",
    "y = y_train.to_numpy()\n",
    "\n",
    "# Create a Boruta feature selector\n",
    "feat_selector = BorutaPy(estimator=LGBMRegressor(), random_state=42)\n",
    "\n",
    "# Find all relevant features\n",
    "feat_selector.fit(X, y)\n",
    "\n",
    "feature_names = np.array(X_train.columns)  \n",
    "\n",
    "# check selected features\n",
    "print(feat_selector.support_)  #Should we accept the feature\n",
    "\n",
    "# check ranking of features\n",
    "print(feat_selector.ranking_) #Rank 1 is the best\n",
    "\n",
    "# call transform() on X to filter it down to selected features\n",
    "X_filtered = feat_selector.transform(X)  #Apply feature selection and return transformed data\n",
    "\n",
    "\"\"\"\n",
    "Review the features\n",
    "\"\"\"\n",
    "# zip feature names, ranks, and decisions \n",
    "feature_ranks = list(zip(feature_names, \n",
    "                         feat_selector.ranking_, \n",
    "                         feat_selector.support_))\n",
    "\n",
    "# print the results\n",
    "for feat in feature_ranks:\n",
    "    print('Feature: {:<30} Rank: {},  Keep: {}'.format(feat[0], feat[1], feat[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/snap/jupyter/common/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "df = pd.read_csv('230611_GMM.csv')\n",
    "# Convert to datetime object\n",
    "df['deviceTime'] = pd.to_datetime(df['deviceTime'])\n",
    "# Convert to Unix timestamp\n",
    "df['unix_timestamp'] = df['deviceTime'].apply(lambda x: x.timestamp())\n",
    "\n",
    "# initialize OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# fit and transform the data\n",
    "encoded = encoder.fit_transform(df[['label']]).toarray()\n",
    "\n",
    "# create new columns in the original dataframe with the encoded values\n",
    "encoded_df = pd.DataFrame(encoded, columns=encoder.get_feature_names(['label']))\n",
    "df = pd.concat([df, encoded_df], axis=1)\n",
    "\n",
    "df = df.drop(['date', 'label', 'vehicleId', 'ending', 'starting', 'gnssPDOP', 'gnssHDOP'], axis = 1)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Select only the columns that have numeric data types and exclude target\n",
    "numeric_cols = df.select_dtypes(include=['float', 'int']).columns\n",
    "numeric_cols = numeric_cols.drop('fuel_diff')\n",
    "\n",
    "# Apply MinMaxScaler only on the numeric columns\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = df.copy()\n",
    "df_scaled[numeric_cols] = scaler.fit_transform(df_scaled[numeric_cols])\n",
    "\n",
    "# The object columns remain unchanged\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "val_mask = df_scaled['new_vehicle_id'].isin(['v1', 'v7', 'v10', 'v5', 'v17'])\n",
    "test_mask = df_scaled['new_vehicle_id'].isin(['v3', 'v8', 'v28', 'v32', 'v2'])\n",
    "train_mask = ~df_scaled['new_vehicle_id'].isin(np.concatenate((val_mask, test_mask)))\n",
    "X_train = df_scaled.loc[train_mask, :].drop(columns=['new_vehicle_id', 'deviceTime', 'fuel_diff' ,'fuel_level'])\n",
    "y_train = df_scaled.loc[train_mask, 'fuel_diff']\n",
    "X_val = df_scaled.loc[val_mask, :].drop(columns=['new_vehicle_id', 'deviceTime', 'fuel_diff', 'fuel_level'])\n",
    "y_val = df_scaled.loc[val_mask, 'fuel_diff']\n",
    "X_test = df_scaled.loc[test_mask, :].drop(columns=['new_vehicle_id', 'deviceTime', 'fuel_diff','fuel_level'])\n",
    "y_test = df_scaled.loc[test_mask, 'fuel_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True False  True False  True False  True\n",
      " False False False]\n",
      "[1 1 1 1 1 1 3 1 2 1 5 1 4 7 6]\n",
      "Feature: speed_generate                 Rank: 1,  Keep: True\n",
      "Feature: batteryVoltage                 Rank: 1,  Keep: True\n",
      "Feature: altitude                       Rank: 1,  Keep: True\n",
      "Feature: heading                        Rank: 1,  Keep: True\n",
      "Feature: lat                            Rank: 1,  Keep: True\n",
      "Feature: lon                            Rank: 1,  Keep: True\n",
      "Feature: axisX                          Rank: 3,  Keep: False\n",
      "Feature: axisY                          Rank: 1,  Keep: True\n",
      "Feature: axisZ                          Rank: 2,  Keep: False\n",
      "Feature: distance (km)                  Rank: 1,  Keep: True\n",
      "Feature: Fuel Capacity (L)              Rank: 5,  Keep: False\n",
      "Feature: unix_timestamp                 Rank: 1,  Keep: True\n",
      "Feature: label_abnormal                 Rank: 4,  Keep: False\n",
      "Feature: label_normal                   Rank: 7,  Keep: False\n",
      "Feature: label_refuel                   Rank: 6,  Keep: False\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from boruta import BorutaPy\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Convert X DataFrame to numpy array\n",
    "X = X_train.to_numpy()\n",
    "y = y_train.to_numpy()\n",
    "\n",
    "# Create a Boruta feature selector\n",
    "feat_selector = BorutaPy(estimator=LGBMRegressor(), random_state=42)\n",
    "\n",
    "# Find all relevant features\n",
    "feat_selector.fit(X, y)\n",
    "\n",
    "feature_names = np.array(X_train.columns)  \n",
    "\n",
    "# check selected features\n",
    "print(feat_selector.support_)  #Should we accept the feature\n",
    "\n",
    "# check ranking of features\n",
    "print(feat_selector.ranking_) #Rank 1 is the best\n",
    "\n",
    "# call transform() on X to filter it down to selected features\n",
    "X_filtered = feat_selector.transform(X)  #Apply feature selection and return transformed data\n",
    "\n",
    "\"\"\"\n",
    "Review the features\n",
    "\"\"\"\n",
    "# zip feature names, ranks, and decisions \n",
    "feature_ranks = list(zip(feature_names, \n",
    "                         feat_selector.ranking_, \n",
    "                         feat_selector.support_))\n",
    "\n",
    "# print the results\n",
    "for feat in feature_ranks:\n",
    "    print('Feature: {:<30} Rank: {},  Keep: {}'.format(feat[0], feat[1], feat[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: speed_generate                 Rank: 1,  Keep: True\n",
      "Feature: batteryVoltage                 Rank: 1,  Keep: True\n",
      "Feature: altitude                       Rank: 1,  Keep: True\n",
      "Feature: gnssHDOP                       Rank: 4,  Keep: False\n",
      "Feature: gnssPDOP                       Rank: 3,  Keep: False\n",
      "Feature: heading                        Rank: 1,  Keep: True\n",
      "Feature: lat                            Rank: 1,  Keep: True\n",
      "Feature: lon                            Rank: 1,  Keep: True\n",
      "Feature: axisX                          Rank: 1,  Keep: True\n",
      "Feature: axisY                          Rank: 1,  Keep: True\n",
      "Feature: axisZ                          Rank: 1,  Keep: True\n",
      "Feature: distance (km)                  Rank: 1,  Keep: True\n",
      "Feature: Engine CC                      Rank: 6,  Keep: False\n",
      "Feature: BDM                            Rank: 8,  Keep: False\n",
      "Feature: BTM                            Rank: 5,  Keep: False\n",
      "Feature: unix_timestamp                 Rank: 1,  Keep: True\n",
      "Feature: label_abnormal                 Rank: 2,  Keep: False\n",
      "Feature: label_normal                   Rank: 1,  Keep: True\n",
      "Feature: label_refuel                   Rank: 7,  Keep: False\n"
     ]
    }
   ],
   "source": [
    "# call transform() on X to filter it down to selected features\n",
    "X_filtered = feat_selector.transform(X)  #Apply feature selection and return transformed data\n",
    "\n",
    "\"\"\"\n",
    "Review the features\n",
    "\"\"\"\n",
    "# zip feature names, ranks, and decisions \n",
    "feature_ranks = list(zip(feature_names, \n",
    "                         feat_selector.ranking_, \n",
    "                         feat_selector.support_))\n",
    "\n",
    "# print the results\n",
    "for feat in feature_ranks:\n",
    "    print('Feature: {:<30} Rank: {},  Keep: {}'.format(feat[0], feat[1], feat[2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
